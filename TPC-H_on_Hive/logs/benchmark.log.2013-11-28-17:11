Running Hive from /opt/hive-0.12.0
Running Hadoop from 
Running Hive query: tpch/q1_pricing_summary_report.hive
13/11/28 17:00:19 INFO Configuration.deprecation: mapred.input.dir.recursive is deprecated. Instead, use mapreduce.input.fileinputformat.input.dir.recursive
13/11/28 17:00:19 INFO Configuration.deprecation: mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
13/11/28 17:00:19 INFO Configuration.deprecation: mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
13/11/28 17:00:19 INFO Configuration.deprecation: mapred.min.split.size.per.rack is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.rack
13/11/28 17:00:19 INFO Configuration.deprecation: mapred.min.split.size.per.node is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.node
13/11/28 17:00:19 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
13/11/28 17:00:19 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative

Logging initialized using configuration in jar:file:/opt/hive-0.12.0/lib/hive-common-0.12.0.jar!/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hadoop-2.2.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hive-0.12.0/lib/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
OK
Time taken: 13.474 seconds
OK
Time taken: 0.29 seconds
OK
Time taken: 0.558 seconds
OK
Time taken: 0.074 seconds
Total MapReduce jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_1385668766299_0001, Tracking URL = http://10.6.40.110/proxy/application_1385668766299_0001/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1385668766299_0001
Hadoop job information for Stage-1: number of mappers: 4; number of reducers: 1
2013-11-28 17:01:15,065 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 45.68 sec
MapReduce Total cumulative CPU time: 45 seconds 680 msec
Ended Job = job_1385668766299_0001
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_1385668766299_0002, Tracking URL = http://10.6.40.110/proxy/application_1385668766299_0002/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1385668766299_0002
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2013-11-28 17:01:36,414 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 1.91 sec
MapReduce Total cumulative CPU time: 1 seconds 910 msec
Ended Job = job_1385668766299_0002
Loading data to table default.q1_pricing_summary_report
Table default.q1_pricing_summary_report stats: [num_partitions: 0, num_files: 1, num_rows: 0, total_size: 571, raw_data_size: 0]
MapReduce Jobs Launched: 
Job 0: Map: 4  Reduce: 1   Cumulative CPU: 45.68 sec   HDFS Read: 759884717 HDFS Write: 423 SUCCESS
Job 1: Map: 1  Reduce: 1   Cumulative CPU: 1.91 sec   HDFS Read: 790 HDFS Write: 571 SUCCESS
Total MapReduce CPU Time Spent: 47 seconds 590 msec
OK
Time taken: 61.485 seconds
Time:80.41
Running Hive query: tpch/q2_minimum_cost_supplier.hive
13/11/28 17:01:40 INFO Configuration.deprecation: mapred.input.dir.recursive is deprecated. Instead, use mapreduce.input.fileinputformat.input.dir.recursive
13/11/28 17:01:40 INFO Configuration.deprecation: mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
13/11/28 17:01:40 INFO Configuration.deprecation: mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
13/11/28 17:01:40 INFO Configuration.deprecation: mapred.min.split.size.per.rack is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.rack
13/11/28 17:01:40 INFO Configuration.deprecation: mapred.min.split.size.per.node is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.node
13/11/28 17:01:40 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
13/11/28 17:01:40 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative

Logging initialized using configuration in jar:file:/opt/hive-0.12.0/lib/hive-common-0.12.0.jar!/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hadoop-2.2.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hive-0.12.0/lib/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
OK
Time taken: 22.158 seconds
OK
Time taken: 0.327 seconds
OK
Time taken: 0.399 seconds
OK
Time taken: 0.292 seconds
OK
Time taken: 0.348 seconds
OK
Time taken: 0.276 seconds
OK
Time taken: 0.178 seconds
OK
Time taken: 0.451 seconds
OK
Time taken: 0.574 seconds
OK
Time taken: 0.122 seconds
OK
Time taken: 0.158 seconds
OK
Time taken: 0.123 seconds
OK
Time taken: 0.138 seconds
OK
Time taken: 0.108 seconds
OK
Time taken: 0.066 seconds
OK
Time taken: 0.066 seconds
Total MapReduce jobs = 7
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hadoop-2.2.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hive-0.12.0/lib/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
13/11/28 17:02:18 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/11/28 17:02:18 WARN conf.Configuration: file:/tmp/hadoop/hive_2013-11-28_17-02-09_087_8220849327027244820-1/-local-10016/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
13/11/28 17:02:18 WARN conf.Configuration: file:/tmp/hadoop/hive_2013-11-28_17-02-09_087_8220849327027244820-1/-local-10016/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
13/11/28 17:02:18 INFO Configuration.deprecation: mapred.input.dir.recursive is deprecated. Instead, use mapreduce.input.fileinputformat.input.dir.recursive
13/11/28 17:02:19 INFO Configuration.deprecation: mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
13/11/28 17:02:19 INFO Configuration.deprecation: mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
13/11/28 17:02:19 INFO Configuration.deprecation: mapred.min.split.size.per.rack is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.rack
13/11/28 17:02:19 INFO Configuration.deprecation: mapred.min.split.size.per.node is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.node
13/11/28 17:02:19 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
13/11/28 17:02:19 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
Execution log at: /tmp/hadoop/.log
2013-11-28 05:02:20	Starting to launch local task to process map join;	maximum memory = 477102080
2013-11-28 05:02:22	Dump the side-table into file: file:/tmp/hadoop/hive_2013-11-28_17-02-09_087_8220849327027244820-1/-local-10013/HashTable-Stage-15/MapJoin-mapfile41--.hashtable
2013-11-28 05:02:22	Upload 1 File to: file:/tmp/hadoop/hive_2013-11-28_17-02-09_087_8220849327027244820-1/-local-10013/HashTable-Stage-15/MapJoin-mapfile41--.hashtable
2013-11-28 05:02:22	Dump the side-table into file: file:/tmp/hadoop/hive_2013-11-28_17-02-09_087_8220849327027244820-1/-local-10013/HashTable-Stage-15/MapJoin-mapfile51--.hashtable
2013-11-28 05:02:22	Upload 1 File to: file:/tmp/hadoop/hive_2013-11-28_17-02-09_087_8220849327027244820-1/-local-10013/HashTable-Stage-15/MapJoin-mapfile51--.hashtable
2013-11-28 05:02:22	End of local task; Time Taken: 2.357 sec.
Execution completed successfully
Mapred Local Task Succeeded . Convert the Join into MapJoin
Mapred Local Task Succeeded . Convert the Join into MapJoin
Launching Job 1 out of 7
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1385668766299_0003, Tracking URL = http://10.6.40.110/proxy/application_1385668766299_0003/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1385668766299_0003
Hadoop job information for Stage-15: number of mappers: 1; number of reducers: 0
2013-11-28 17:02:36,348 Stage-15 map = 100%,  reduce = 0%, Cumulative CPU 1.52 sec
MapReduce Total cumulative CPU time: 1 seconds 520 msec
Ended Job = job_1385668766299_0003
Stage-19 is filtered out by condition resolver.
Stage-20 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 7
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_1385668766299_0004, Tracking URL = http://10.6.40.110/proxy/application_1385668766299_0004/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1385668766299_0004
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2013-11-28 17:03:01,482 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 12.25 sec
MapReduce Total cumulative CPU time: 12 seconds 250 msec
Ended Job = job_1385668766299_0004
Stage-17 is filtered out by condition resolver.
Stage-18 is filtered out by condition resolver.
Stage-3 is selected by condition resolver.
Launching Job 3 out of 7
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_1385668766299_0005, Tracking URL = http://10.6.40.110/proxy/application_1385668766299_0005/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1385668766299_0005
Hadoop job information for Stage-3: number of mappers: 2; number of reducers: 1
2013-11-28 17:03:26,834 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 10.76 sec
MapReduce Total cumulative CPU time: 10 seconds 760 msec
Ended Job = job_1385668766299_0005
Loading data to table default.q2_minimum_cost_supplier_tmp1
Table default.q2_minimum_cost_supplier_tmp1 stats: [num_partitions: 0, num_files: 1, num_rows: 0, total_size: 109507, raw_data_size: 0]
MapReduce Jobs Launched: 
Job 0: Map: 1   Cumulative CPU: 1.52 sec   HDFS Read: 2424 HDFS Write: 324185 SUCCESS
Job 1: Map: 2  Reduce: 1   Cumulative CPU: 12.25 sec   HDFS Read: 119309372 HDFS Write: 27325124 SUCCESS
Job 2: Map: 2  Reduce: 1   Cumulative CPU: 10.76 sec   HDFS Read: 51460812 HDFS Write: 109507 SUCCESS
Total MapReduce CPU Time Spent: 24 seconds 530 msec
OK
Time taken: 78.369 seconds
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_1385668766299_0006, Tracking URL = http://10.6.40.110/proxy/application_1385668766299_0006/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1385668766299_0006
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2013-11-28 17:03:45,541 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 1.83 sec
MapReduce Total cumulative CPU time: 1 seconds 830 msec
Ended Job = job_1385668766299_0006
Loading data to table default.q2_minimum_cost_supplier_tmp2
Table default.q2_minimum_cost_supplier_tmp2 stats: [num_partitions: 0, num_files: 1, num_rows: 0, total_size: 6083, raw_data_size: 0]
MapReduce Jobs Launched: 
Job 0: Map: 1  Reduce: 1   Cumulative CPU: 1.83 sec   HDFS Read: 109743 HDFS Write: 6083 SUCCESS
Total MapReduce CPU Time Spent: 1 seconds 830 msec
OK
Time taken: 18.583 seconds
Total MapReduce jobs = 1
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hadoop-2.2.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hive-0.12.0/lib/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
13/11/28 17:03:49 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/11/28 17:03:49 WARN conf.Configuration: file:/tmp/hadoop/hive_2013-11-28_17-03-46_039_407168246041273224-1/-local-10006/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
13/11/28 17:03:49 WARN conf.Configuration: file:/tmp/hadoop/hive_2013-11-28_17-03-46_039_407168246041273224-1/-local-10006/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
13/11/28 17:03:49 INFO Configuration.deprecation: mapred.input.dir.recursive is deprecated. Instead, use mapreduce.input.fileinputformat.input.dir.recursive
13/11/28 17:03:49 INFO Configuration.deprecation: mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
13/11/28 17:03:49 INFO Configuration.deprecation: mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
13/11/28 17:03:49 INFO Configuration.deprecation: mapred.min.split.size.per.rack is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.rack
13/11/28 17:03:49 INFO Configuration.deprecation: mapred.min.split.size.per.node is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.node
13/11/28 17:03:49 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
13/11/28 17:03:49 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
Execution log at: /tmp/hadoop/.log
2013-11-28 05:03:52	Starting to launch local task to process map join;	maximum memory = 477102080
2013-11-28 05:03:53	Dump the side-table into file: file:/tmp/hadoop/hive_2013-11-28_17-03-46_039_407168246041273224-1/-local-10003/HashTable-Stage-2/MapJoin-mapfile61--.hashtable
2013-11-28 05:03:54	Upload 1 File to: file:/tmp/hadoop/hive_2013-11-28_17-03-46_039_407168246041273224-1/-local-10003/HashTable-Stage-2/MapJoin-mapfile61--.hashtable
2013-11-28 05:03:54	End of local task; Time Taken: 1.085 sec.
Execution completed successfully
Mapred Local Task Succeeded . Convert the Join into MapJoin
Mapred Local Task Succeeded . Convert the Join into MapJoin
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_1385668766299_0007, Tracking URL = http://10.6.40.110/proxy/application_1385668766299_0007/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1385668766299_0007
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2013-11-28 17:04:12,640 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 2.15 sec
MapReduce Total cumulative CPU time: 2 seconds 150 msec
Ended Job = job_1385668766299_0007
Loading data to table default.q2_minimum_cost_supplier
Table default.q2_minimum_cost_supplier stats: [num_partitions: 0, num_files: 1, num_rows: 0, total_size: 16329, raw_data_size: 0]
MapReduce Jobs Launched: 
Job 0: Map: 1  Reduce: 1   Cumulative CPU: 2.15 sec   HDFS Read: 109743 HDFS Write: 16329 SUCCESS
Total MapReduce CPU Time Spent: 2 seconds 150 msec
OK
Time taken: 27.216 seconds
Time:155.93
Running Hive query: tpch/q3_shipping_priority.hive
13/11/28 17:04:14 INFO Configuration.deprecation: mapred.input.dir.recursive is deprecated. Instead, use mapreduce.input.fileinputformat.input.dir.recursive
13/11/28 17:04:14 INFO Configuration.deprecation: mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
13/11/28 17:04:14 INFO Configuration.deprecation: mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
13/11/28 17:04:14 INFO Configuration.deprecation: mapred.min.split.size.per.rack is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.rack
13/11/28 17:04:14 INFO Configuration.deprecation: mapred.min.split.size.per.node is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.node
13/11/28 17:04:14 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
13/11/28 17:04:14 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative

Logging initialized using configuration in jar:file:/opt/hive-0.12.0/lib/hive-common-0.12.0.jar!/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hadoop-2.2.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hive-0.12.0/lib/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
OK
Time taken: 10.183 seconds
OK
Time taken: 0.14 seconds
OK
Time taken: 0.173 seconds
OK
Time taken: 0.248 seconds
OK
Time taken: 0.602 seconds
OK
Time taken: 0.101 seconds
OK
Time taken: 0.158 seconds
OK
Time taken: 0.141 seconds
Total MapReduce jobs = 7
Stage-16 is filtered out by condition resolver.
Stage-1 is selected by condition resolver.
Launching Job 1 out of 7
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_1385668766299_0008, Tracking URL = http://10.6.40.110/proxy/application_1385668766299_0008/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1385668766299_0008
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 1
2013-11-28 17:05:04,203 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 18.22 sec
MapReduce Total cumulative CPU time: 18 seconds 220 msec
Ended Job = job_1385668766299_0008
Stage-14 is filtered out by condition resolver.
Stage-15 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 7
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_1385668766299_0009, Tracking URL = http://10.6.40.110/proxy/application_1385668766299_0009/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1385668766299_0009
Hadoop job information for Stage-2: number of mappers: 5; number of reducers: 1
2013-11-28 17:05:36,664 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 45.27 sec
MapReduce Total cumulative CPU time: 45 seconds 270 msec
Ended Job = job_1385668766299_0009
Launching Job 3 out of 7
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_1385668766299_0010, Tracking URL = http://10.6.40.110/proxy/application_1385668766299_0010/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1385668766299_0010
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2013-11-28 17:05:58,575 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.26 sec
MapReduce Total cumulative CPU time: 5 seconds 260 msec
Ended Job = job_1385668766299_0010
Launching Job 4 out of 7
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_1385668766299_0011, Tracking URL = http://10.6.40.110/proxy/application_1385668766299_0011/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1385668766299_0011
Hadoop job information for Stage-4: number of mappers: 1; number of reducers: 1
2013-11-28 17:06:17,557 Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 4.17 sec
MapReduce Total cumulative CPU time: 4 seconds 170 msec
Ended Job = job_1385668766299_0011
Loading data to table default.q3_shipping_priority
Table default.q3_shipping_priority stats: [num_partitions: 0, num_files: 1, num_rows: 0, total_size: 340, raw_data_size: 0]
MapReduce Jobs Launched: 
Job 0: Map: 3  Reduce: 1   Cumulative CPU: 18.22 sec   HDFS Read: 196303005 HDFS Write: 4901873 SUCCESS
Job 1: Map: 5  Reduce: 1   Cumulative CPU: 45.27 sec   HDFS Read: 764786957 HDFS Write: 481131 SUCCESS
Job 2: Map: 1  Reduce: 1   Cumulative CPU: 5.26 sec   HDFS Read: 481498 HDFS Write: 481131 SUCCESS
Job 3: Map: 1  Reduce: 1   Cumulative CPU: 4.17 sec   HDFS Read: 481498 HDFS Write: 340 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 12 seconds 920 msec
OK
Time taken: 109.103 seconds
Time:124.90
Running Hive query: tpch/q4_order_priority.hive
13/11/28 17:06:20 INFO Configuration.deprecation: mapred.input.dir.recursive is deprecated. Instead, use mapreduce.input.fileinputformat.input.dir.recursive
13/11/28 17:06:20 INFO Configuration.deprecation: mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
13/11/28 17:06:20 INFO Configuration.deprecation: mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
13/11/28 17:06:20 INFO Configuration.deprecation: mapred.min.split.size.per.rack is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.rack
13/11/28 17:06:20 INFO Configuration.deprecation: mapred.min.split.size.per.node is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.node
13/11/28 17:06:20 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
13/11/28 17:06:20 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative

Logging initialized using configuration in jar:file:/opt/hive-0.12.0/lib/hive-common-0.12.0.jar!/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hadoop-2.2.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hive-0.12.0/lib/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
OK
Time taken: 10.372 seconds
OK
Time taken: 0.136 seconds
OK
Time taken: 0.272 seconds
OK
Time taken: 0.131 seconds
OK
Time taken: 0.238 seconds
OK
Time taken: 0.05 seconds
OK
Time taken: 0.049 seconds
OK
Time taken: 0.042 seconds
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_1385668766299_0012, Tracking URL = http://10.6.40.110/proxy/application_1385668766299_0012/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1385668766299_0012
Hadoop job information for Stage-1: number of mappers: 4; number of reducers: 1
2013-11-28 17:07:04,121 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 33.02 sec
MapReduce Total cumulative CPU time: 33 seconds 20 msec
Ended Job = job_1385668766299_0012
Loading data to table default.q4_order_priority_tmp
Table default.q4_order_priority_tmp stats: [num_partitions: 0, num_files: 1, num_rows: 0, total_size: 10748076, raw_data_size: 0]
MapReduce Jobs Launched: 
Job 0: Map: 4  Reduce: 1   Cumulative CPU: 33.02 sec   HDFS Read: 759884717 HDFS Write: 10748076 SUCCESS
Total MapReduce CPU Time Spent: 33 seconds 20 msec
OK
Time taken: 31.152 seconds
Total MapReduce jobs = 4
Stage-9 is selected by condition resolver.
Stage-1 is filtered out by condition resolver.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hadoop-2.2.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hive-0.12.0/lib/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
13/11/28 17:07:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/11/28 17:07:13 WARN conf.Configuration: file:/tmp/hadoop/hive_2013-11-28_17-07-04_935_915380853784643218-1/-local-10007/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
13/11/28 17:07:14 WARN conf.Configuration: file:/tmp/hadoop/hive_2013-11-28_17-07-04_935_915380853784643218-1/-local-10007/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
13/11/28 17:07:14 INFO Configuration.deprecation: mapred.input.dir.recursive is deprecated. Instead, use mapreduce.input.fileinputformat.input.dir.recursive
13/11/28 17:07:14 INFO Configuration.deprecation: mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
13/11/28 17:07:14 INFO Configuration.deprecation: mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
13/11/28 17:07:14 INFO Configuration.deprecation: mapred.min.split.size.per.rack is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.rack
13/11/28 17:07:14 INFO Configuration.deprecation: mapred.min.split.size.per.node is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.node
13/11/28 17:07:14 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
13/11/28 17:07:14 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
Execution log at: /tmp/hadoop/.log
2013-11-28 05:07:18	Starting to launch local task to process map join;	maximum memory = 477102080
2013-11-28 05:07:21	Processing rows:	200000	Hashtable size:	199999	Memory usage:	97021240	percentage:	0.203
2013-11-28 05:07:21	Processing rows:	300000	Hashtable size:	299999	Memory usage:	108803736	percentage:	0.228
2013-11-28 05:07:21	Processing rows:	400000	Hashtable size:	399999	Memory usage:	120746328	percentage:	0.253
2013-11-28 05:07:23	Processing rows:	500000	Hashtable size:	499999	Memory usage:	57534984	percentage:	0.121
2013-11-28 05:07:23	Processing rows:	600000	Hashtable size:	599999	Memory usage:	66949112	percentage:	0.14
2013-11-28 05:07:23	Processing rows:	700000	Hashtable size:	699999	Memory usage:	76363224	percentage:	0.16
2013-11-28 05:07:23	Processing rows:	800000	Hashtable size:	799999	Memory usage:	92283152	percentage:	0.193
2013-11-28 05:07:23	Processing rows:	900000	Hashtable size:	899999	Memory usage:	101697288	percentage:	0.213
2013-11-28 05:07:24	Processing rows:	1000000	Hashtable size:	999999	Memory usage:	111111440	percentage:	0.233
2013-11-28 05:07:24	Processing rows:	1100000	Hashtable size:	1099999	Memory usage:	118642744	percentage:	0.249
2013-11-28 05:07:24	Processing rows:	1200000	Hashtable size:	1199999	Memory usage:	128056872	percentage:	0.268
2013-11-28 05:07:24	Processing rows:	1300000	Hashtable size:	1299999	Memory usage:	137470984	percentage:	0.288
2013-11-28 05:07:24	Dump the side-table into file: file:/tmp/hadoop/hive_2013-11-28_17-07-04_935_915380853784643218-1/-local-10004/HashTable-Stage-6/MapJoin-mapfile01--.hashtable
2013-11-28 05:07:25	Upload 1 File to: file:/tmp/hadoop/hive_2013-11-28_17-07-04_935_915380853784643218-1/-local-10004/HashTable-Stage-6/MapJoin-mapfile01--.hashtable
2013-11-28 05:07:25	End of local task; Time Taken: 6.82 sec.
Execution completed successfully
Mapred Local Task Succeeded . Convert the Join into MapJoin
Mapred Local Task Succeeded . Convert the Join into MapJoin
Launching Job 2 out of 4
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1385668766299_0013, Tracking URL = http://10.6.40.110/proxy/application_1385668766299_0013/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1385668766299_0013
Hadoop job information for Stage-6: number of mappers: 2; number of reducers: 0
2013-11-28 17:11:31,957 Stage-6 map = 0%,  reduce = 0%
Ended Job = job_1385668766299_0013 with errors
Error during job, obtaining debugging information...
Examining task ID: task_1385668766299_0013_m_000001 (and more) from job job_1385668766299_0013

Task with the most failures(4): 
-----
Task ID:
  task_1385668766299_0013_m_000000

URL:
  http://hadoop11:8088/taskdetails.jsp?jobid=job_1385668766299_0013&tipid=task_1385668766299_0013_m_000000
-----
Diagnostic Messages for this Task:
Error: GC overhead limit exceeded

FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
MapReduce Jobs Launched: 
Job 0: Map: 2   FAIL
Total MapReduce CPU Time Spent: -1 msec
Command exited with non-zero status 2
Time:313.91
Running Hive query: tpch/q5_local_supplier_volume.hive
13/11/28 17:11:34 INFO Configuration.deprecation: mapred.input.dir.recursive is deprecated. Instead, use mapreduce.input.fileinputformat.input.dir.recursive
13/11/28 17:11:34 INFO Configuration.deprecation: mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
13/11/28 17:11:34 INFO Configuration.deprecation: mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
13/11/28 17:11:34 INFO Configuration.deprecation: mapred.min.split.size.per.rack is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.rack
13/11/28 17:11:34 INFO Configuration.deprecation: mapred.min.split.size.per.node is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.node
13/11/28 17:11:34 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
13/11/28 17:11:34 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative

Logging initialized using configuration in jar:file:/opt/hive-0.12.0/lib/hive-common-0.12.0.jar!/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hadoop-2.2.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hive-0.12.0/lib/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Running Hive query: tpch/q6_forecast_revenue_change.hive
Running Hive query: tpch/q7_volume_shipping.hive
Running Hive query: tpch/q8_national_market_share.hive
Running Hive query: tpch/q9_product_type_profit.hive
Running Hive query: tpch/q10_returned_item.hive
Running Hive query: tpch/q11_important_stock.hive
Running Hive query: tpch/q12_shipping.hive
Running Hive query: tpch/q13_customer_distribution.hive
Running Hive query: tpch/q14_promotion_effect.hive
Running Hive query: tpch/q15_top_supplier.hive
Running Hive query: tpch/q16_parts_supplier_relationship.hive
Running Hive query: tpch/q17_small_quantity_order_revenue.hive
Running Hive query: tpch/q18_large_volume_customer.hive
Running Hive query: tpch/q19_discounted_revenue.hive
Running Hive query: tpch/q20_potential_part_promotion.hive
Running Hive query: tpch/q21_suppliers_who_kept_orders_waiting.hive
Running Hive query: tpch/q22_global_sales_opportunity.hive
